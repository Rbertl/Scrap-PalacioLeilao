import json
import pickle
import os
import unicodedata
import re
import csv
import time
from datetime import datetime
import config
from colorama import Fore, Style

try:
    from sentence_transformers import SentenceTransformer, util
    import torch
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# --- OTIMIZA√á√ÉO DE VELOCIDADE: CACHE GLOBAL ---
# Mant√©m o modelo na mem√≥ria RAM para n√£o recarregar a cada busca
MODELO_CACHE = None

def get_model():
    """Carrega o modelo apenas se ainda n√£o estiver na mem√≥ria."""
    global MODELO_CACHE
    if not AI_AVAILABLE:
        return None
        
    if MODELO_CACHE is None:
        print(Fore.YELLOW + "üß† Carregando modelo de IA pela primeira vez (isso acontece s√≥ uma vez)..." + Style.RESET_ALL)
        MODELO_CACHE = SentenceTransformer(config.MODEL_NAME)
    return MODELO_CACHE

def normalizar_texto(texto):
    """
    Remove acentos, coloca em min√∫sculas e TROCA PONTUA√á√ÉO POR ESPA√áO.
    """
    if not texto: return ""
    nfkd = unicodedata.normalize('NFKD', texto)
    sem_acentos = u"".join([c for c in nfkd if not unicodedata.combining(c)]).lower()
    texto_limpo = re.sub(r'[^a-z0-9]', ' ', sem_acentos)
    return " ".join(texto_limpo.split())

def exportar_para_csv(resultados, termo):
    """Gera um arquivo CSV compat√≠vel com Excel."""
    if not resultados:
        print("Nada para exportar.")
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    termo_limpo = re.sub(r'[^a-zA-Z0-9]', '_', termo)
    nome_arquivo = f"resultado_{termo_limpo}_{timestamp}.csv"
    caminho_arquivo = os.path.join(config.DATA_DIR, nome_arquivo)

    try:
        # encoding='utf-8-sig' √© essencial para o Excel ler acentos corretamente
        with open(caminho_arquivo, mode='w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f, delimiter=';') # Ponto e v√≠rgula √© o padr√£o Excel Brasil
            
            # Cabe√ßalho
            writer.writerow(['Relev√¢ncia', 'Tipo Match', 'Lote', 'Data', 'Local', 'Descri√ß√£o', 'Link'])
            
            for item in resultados:
                writer.writerow([
                    f"{item['score']:.2f}",
                    item['tipo_match'],
                    item['lote'],
                    item['data'],
                    item['local'],
                    item['texto_completo'],
                    item['url']
                ])
        
        print(Fore.GREEN + f"\n‚úÖ Relat√≥rio salvo com sucesso em: {caminho_arquivo}")
        print(f"   (Abra com o Excel)")
    except Exception as e:
        print(Fore.RED + f"Erro ao salvar arquivo: {e}")

def realizar_busca(termo):
    if not AI_AVAILABLE:
        print(Fore.RED + "‚ùå Biblioteca de IA faltando (sentence-transformers)." + Style.RESET_ALL)
        return

    if not os.path.exists(config.EMBEDDINGS_FILE) or not os.path.exists(config.PROCESSED_DATA_FILE):
        print(Fore.RED + "‚ùå Dados de intelig√™ncia n√£o encontrados. Rode a op√ß√£o 2 (Processar) primeiro." + Style.RESET_ALL)
        return

    # Usa o Cache para velocidade instant√¢nea nas buscas subsequentes
    model = get_model()
    
    with open(config.EMBEDDINGS_FILE, 'rb') as f:
        embeddings_banco = pickle.load(f)
    
    with open(config.PROCESSED_DATA_FILE, 'r', encoding='utf-8') as f:
        dados = json.load(f)

    # --- ESTRAT√âGIA 1: BUSCA SEM√ÇNTICA (IA) ---
    query_embedding = model.encode(termo, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, embeddings_banco, top_k=50)[0]
    
    resultados_combinados = {}
    for hit in hits:
        idx = hit['corpus_id']
        resultados_combinados[idx] = hit['score']

    # --- ESTRAT√âGIA 2: BUSCA TEXTUAL INTELIGENTE ---
    termo_norm = normalizar_texto(termo)
    palavras_busca = termo_norm.split() 
    itens_com_match_textual = set()
    
    print(Fore.CYAN + "üîç Cruzando dados (IA + Texto)..." + Style.RESET_ALL)
    
    for idx, item in enumerate(dados):
        texto_item = normalizar_texto(item['texto_completo'])
        palavras_item_set = set(texto_item.split())
        bonus_texto = 0.0
        
        # 1. Match Exato
        if termo_norm in texto_item:
            bonus_texto += 0.4
            
        # 2. Match Palavra/Raiz
        matches_palavras = 0
        for palavra in palavras_busca:
            match_encontrado = False
            if len(palavra) < 4:
                if palavra in palavras_item_set: match_encontrado = True
            else:
                if palavra in texto_item:
                    match_encontrado = True
                else:
                    # Stemming simples (ra√≠zes)
                    raiz = palavra.rstrip('s')
                    if raiz.endswith(('o', 'a', 'e')): raiz = raiz[:-1]
                    if len(raiz) >= 3 and raiz in palavras_item_set:
                        match_encontrado = True

            if match_encontrado: matches_palavras += 1
        
        if matches_palavras > 0:
            fator_match = matches_palavras / len(palavras_busca)
            bonus_texto += (fator_match * 0.3)
            itens_com_match_textual.add(idx)

        if bonus_texto > 0:
            score_atual = resultados_combinados.get(idx, 0.0)
            resultados_combinados[idx] = score_atual + bonus_texto

    # --- ORDENA√á√ÉO E EXIBI√á√ÉO ---
    ranking_final = sorted(resultados_combinados.items(), key=lambda x: x[1], reverse=True)
    
    lista_exportacao = [] # Lista para guardar dados para o Excel
    encontrou = False
    
    print(f"\nüîé Resultados para: '{termo}'\n" + "="*60)
    
    contador = 0
    for idx, score in ranking_final:
        limite_minimo = 0.10 if idx in itens_com_match_textual else 0.35
        
        if score > limite_minimo: 
            item = dados[idx]
            encontrou = True
            contador += 1
            if contador > 20: break # Limite de exibi√ß√£o no terminal
            
            desc_curta = item['texto_completo'][:150].replace('\n', ' ') + "..."
            
            tipo_match = "Conceito IA"
            if idx in itens_com_match_textual:
                cor_score = Fore.GREEN
                tipo_match = "Texto + IA"
            else:
                cor_score = Fore.MAGENTA
            
            print(f"{cor_score}#{contador} [Score: {score:.2f}] ({tipo_match}) {Style.RESET_ALL}Lote: {item['lote']}")
            print(f"   üìù {desc_curta}")
            print(f"   üîó {item['url']}")
            print(Fore.CYAN + "-" * 60 + Style.RESET_ALL)
            
            # Prepara objeto para exporta√ß√£o
            item_export = item.copy()
            item_export['score'] = score
            item_export['tipo_match'] = tipo_match
            lista_exportacao.append(item_export)
    
    if not encontrou:
        print(Fore.RED + "üòï Nenhum item relevante encontrado." + Style.RESET_ALL)
    elif lista_exportacao:
        # Pergunta se quer exportar
        print(f"\nForam encontrados {len(lista_exportacao)} itens relevantes.")
        opt = input(Fore.YELLOW + "Deseja exportar estes resultados para Excel (CSV)? [S/N]: " + Style.RESET_ALL).upper()
        if opt == 'S':
            exportar_para_csv(lista_exportacao, termo)